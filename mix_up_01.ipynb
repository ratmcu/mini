{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu in use\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import models.cnn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision \n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"gpu in use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data and \n",
    "batch_size = 32\n",
    "mnist_dataset = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset,\n",
    "  batch_size=batch_size, shuffle=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                              train=False, \n",
    "                                              transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                      batch_size=10000, \n",
    "                                      shuffle=False)\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "#batch_size = 100\n",
    "learning_rate = 0.001\n",
    "hp = {'input_size':input_size,\n",
    "      'num_classes':num_classes,\n",
    "      'num_epochs':num_epochs,\n",
    "      'batch_size':100 ,\n",
    "      'learning_rate':learning_rate,\n",
    "      'hidden_n':1000}\n",
    "\n",
    "cnn = models.cnn.ConvNet(hp) # models/cnn.py could be edited to change the network\n",
    "def convert_to_one_hot_labels( input, target):\n",
    "        tmp = input.new(target.size(0), 10).fill_(0)\n",
    "        tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(torch.Size([batch_size//2, 1]), dtype=torch.float32, device='cpu')*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    #print(images1.size(),images2.size(),labels1.size(),labels2.size())\n",
    "    labels = convert_to_one_hot_labels(images, labels)\n",
    "    labels_1 = labels.narrow(0,0,batch_size//2)\n",
    "    labels_2 = labels.narrow(0,batch_size//2,batch_size//2)\n",
    "    images_1 = images.narrow(0,0,batch_size//2)\n",
    "    images_2 = images.narrow(0,batch_size//2,batch_size//2)\n",
    "    r = m.sample()\n",
    "    a = r * torch.ones(torch.Size([batch_size//2, 28*28]), dtype=torch.float32, device='cpu')\n",
    "    a = a.reshape(batch_size//2,1,28,28)\n",
    "    labels = r*labels_1+(1-r)*labels_2\n",
    "    images = a*images_1+(1-a)*images_2\n",
    "    cnn.train_a_batch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model 'conv' on the 10000 test images: 99.07 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.07"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_dataset.append(mnist_dataset[1])\n",
    "adv_set1 = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "adv_set2 = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "train_loader1 = torch.utils.data.DataLoader(adv_set1, batch_size=32, shuffle=True)\n",
    "train_loader2 = torch.utils.data.DataLoader(adv_set2, batch_size=32, shuffle=False)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot_labels( input, target):\n",
    "        tmp = input.new(target.size(0), 10).fill_(0)\n",
    "        tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(torch.Size([batch_size, 1]), dtype=torch.float32, device='cpu')*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "for  (images1, labels1), (images2, labels2) in zip(train_loader1, train_loader2):\n",
    "    #print(images1.size(),images2.size(),labels1.size(),labels2.size())\n",
    "    labels1 = convert_to_one_hot_labels(images1, labels1)\n",
    "    labels2 = convert_to_one_hot_labels(images2, labels2)\n",
    "    r = m.sample()\n",
    "    o = r * torch.ones(torch.Size([batch_size, 28*28]), dtype=torch.float32, device='cpu')\n",
    "    o = o.reshape(batch_size,1,28,28)\n",
    "#     print((r*labels1+(1-r)*labels2))\n",
    "#     print(o*images1+(1-o)*images2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  32\n",
    "t = torch.ones(torch.Size([batch_size//2, 1]), dtype=torch.float32, device='cpu')*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "for i, (images, labels) in enumerate(train_loader1):\n",
    "    #print(images1.size(),images2.size(),labels1.size(),labels2.size())\n",
    "    labels = convert_to_one_hot_labels(images, labels)\n",
    "    labels_1 = labels.narrow(0,0,batch_size//2)\n",
    "    labels_2 = labels.narrow(0,batch_size//2,batch_size//2)\n",
    "    images_1 = images.narrow(0,0,batch_size//2)\n",
    "    images_2 = images.narrow(0,batch_size//2,batch_size//2)\n",
    "    r = m.sample()\n",
    "    a = r * torch.ones(torch.Size([batch_size//2, 28*28]), dtype=torch.float32, device='cpu')\n",
    "    a = a.reshape(batch_size//2,1,28,28)\n",
    "    labels = r*labels_1+(1-r)*labels_2\n",
    "    images = a*images_1+(1-a)*images_2\n",
    "    cnn.train_a_batch(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.ones([1,2], dtype=torch.float64)*0.5\n",
    "t = torch.ones([32,1])*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "m.sample().squeeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_set1[1][0]*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cifar10 = datasets.CIFAR10('/home/ratmcu/Documents/CSI5138/ex4/vae_ex/kuc/pytorch-vae/datasets/cifar10/', \n",
    "                         train=True, download=False, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_set2[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=torch.tensor(1)\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = torch.ones(torch.Size([32, 1, 28, 28]), dtype=torch.float64, device='cuda')\n",
    "lbl = torch.ones(torch.Size([32]), dtype=torch.float64, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = torch.ones(torch.Size([1, 32]), dtype=torch.float64, device='cuda')*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "m.sample().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.t()*torch.ones(torch.Size([2,1,28, 28]), dtype=torch.float64, device='cuda').squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(torch.Size([2,1,28, 28]), dtype=torch.float64, device='cuda').squeeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(torch.Size([28, 28]), dtype=torch.float64, device='cuda')*0.7\n",
    "o = torch.ones(torch.Size([32, 1]), dtype=torch.float64, device='cuda')\n",
    "g =  torch.ones(torch.Size([32, 28]), dtype=torch.float64, device='cuda')\n",
    "l = torch.ones(torch.Size([32, 28, 28]), dtype=torch.float64, device='cuda')*0.7\n",
    "k = (o*g)*l\n",
    "t *torch.ones(torch.Size([32, 1, 28, 28]), dtype=torch.float64, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.t().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(torch.Size([32, 1]), dtype=torch.float64, device='cuda')*0.5\n",
    "m = torch.distributions.beta.Beta(t, t)\n",
    "r = m.sample()\n",
    "o = r * torch.ones(torch.Size([32, 28*28]), dtype=torch.float64, device='cuda')\n",
    "o = o.reshape(32,1,28,28)\n",
    "m.sample().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
